{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лабораторная работа 2. Задача распределения ресурсов\n",
    "Реализовать метод динамического программирования для решения задачи о распределении ресурсов.\n",
    "\n",
    "$----------------------------------------------$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Шаг 1.</b> Определим начальные данные для задачи динамического программирования: $Q$ — кол-во единиц ресурса, $P$ — кол-во агентов. Функция прибыли (вида которой мы не знаем) задается в виде матрицы $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 3\n",
    "Q = 3\n",
    "\n",
    "A = np.array([\n",
    "    [0, 1, 2, 3],\n",
    "    [0, 0, 1, 2],\n",
    "    [0, 2, 2, 3]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Шаг 2.</b> Инициируем матрицу B (функция Беллмана — максимальная прибыль от распределения $j$ ресурсов между первыми $i$ агенами) и матрицу C (количество ресурсов для $i$-го агента в оптимальном распределнии $j$ ресурсов между первыми $i$ агентами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.zeros((P + 1, Q + 1))\n",
    "C = np.zeros((P + 1, Q + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Шаг 3.</b> Для дальнейшего решения задачи необходимо будет составить рекуррентное соотношение Беллмана. Рассмотрим два случая распределения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Случай 1.</i> Ресурсы распределяются между одним агентом ($p = 1$). Очевидно, что наибольшая прибыль в этом случае будет получена при передаче всех ресурсов данному агенту. То есть:\n",
    "\n",
    "$$\n",
    "\\forall q \\in \\{0, 1, \\ldots, Q\\} \\space B(p,q) = A(p,q) \\space\\space\\space *\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Случай 2.</i> Если ресурсы распределяются между несколькими агентами $(p \\geq 2)$, то можно применить циклическую логику к составлению соотношений.\n",
    "\n",
    "Так например, если мы отдаем $p$-му агенту 0 единиц ресурсов, то получаем от него $A(p, 0)$ прибыли. Разделив остаток ресурсов ($q$) между оставшимися агентами ($p-1$, в порядке номера) мы получим $B(p-1, q)$ максимальной прибыли. Итого будет прибыли:\n",
    "\n",
    "$$\n",
    "A(p, 0) + B(p-1, q)\n",
    "$$\n",
    "\n",
    "Аналогичный ход мысли в случае с передачей 1 единицы ресурса $p$-му агенту, получим: \n",
    "\n",
    "$$\n",
    "A(p, 1) + B(p-1, q - 1)\n",
    "$$\n",
    "\n",
    "Составим универсальное выражение:\n",
    "\n",
    "$$\n",
    "A(p, i) + B(p-1, q - i)\n",
    "$$\n",
    "\n",
    "Данные выражения справедливы вплоть до выдачи $p$-му агенту $q$ единиц ресурсов. Следовательно, максимальное значение прибыли это максимальное из значений полученных в рассмотренной цепочке. Имеем:\n",
    "\n",
    "$$\n",
    "\\forall q \\in \\{0, 1, \\ldots, Q\\} \\space B(p,q) = \\max_{i \\in \\{0, 1, \\ldots, q\\}} (A(p, i) + B(p - 1, q - i)) \\space\\space\\space **\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реккурентное соотношение Беллмана состоит из уравнений * и **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Прямой ход метода динамического программирования:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B=[[0. 0. 0. 0.]\n",
      " [0. 1. 2. 3.]\n",
      " [0. 1. 2. 3.]\n",
      " [0. 2. 3. 4.]]\n",
      "C=[[0. 0. 0. 0.]\n",
      " [0. 1. 2. 3.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "for p in range(1, P + 1):\n",
    "        for q in range(Q + 1):\n",
    "            if p == 1:\n",
    "                B[p, q] = A[p - 1, q]\n",
    "                C[p, q] = q\n",
    "            else:\n",
    "                max_val_index = max(range(q + 1), key=lambda i: A[p - 1, i] + B[p - 1, q - i])\n",
    "                C[p, q] = max_val_index\n",
    "                \n",
    "                max_profit = A[p - 1, max_val_index] + B[p - 1, q - max_val_index]\n",
    "                B[p, q] = max_profit\n",
    "                \n",
    "print(f\"B={B}\\nC={C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Шаг 4.</b> Для нахождения вектора оптимального распределения $Q$ единиц ресурсов между $P$ агентами необходимо вместе со значениями $B(p, q)$ вычислять значения $C(p, q)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Обратный ход метода динамического программирования:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_buff = P\n",
    "q_buff = Q\n",
    "\n",
    "agent_vec = np.zeros(P)\n",
    "while P > 0:\n",
    "    agent_vec[P - 1] = C[P, Q]\n",
    "    Q -= int(C[P, Q])\n",
    "    P -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем следующие результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная общая прибыль: 4.0\n",
      "Распределение ресурсов между агентами: [2. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Максимальная общая прибыль: {B[p_buff, q_buff]}\")\n",
    "print(f\"Распределение ресурсов между агентами: {agent_vec}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
