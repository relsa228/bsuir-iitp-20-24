--- not autograded ---

Part 1
    blocksize = 20, n = 100: 0.012 ms, 0.017 ms
    blocksize = 20, n = 1000: 1.981 ms, 1.134 ms
    blocksize = 20, n = 2000: 9.294 ms, 6.468 ms
    blocksize = 20, n = 5000: 117.98 ms, 36.116 ms
    blocksize = 20, n = 10000: 660.791 ms, 147.102 ms

    Checkoff Question 1: при n = 1000 (1.981 ms и 1.134 ms)
    Checkoff Question 2: разбиение на блоки позволяют уменьшить количество промахов при
обращений к кешу. На небольших матрицах процесс разбиения тратит больше ресурсов, чем
способен освободить в будущем, поэтому он менее эфективен. На больших матрицах выгода от 
разбиения на блоки становится очевидной, так как количество обращений к кешу увеличивается,
следовательно, уменьшение количества промахов играет более весомую роль в оптимизации алгоритма.

Part 2
    blocksize = 50, n = 10000: 649 ms, 116 ms
    blocksize = 100, n = 10000: 653 ms, 118 ms
    blocksize = 500, n = 10000: 654 ms, 79 ms
    blocksize = 1000, n = 10000: 652 ms, 116 ms
    blocksize = 5000, n = 10000: 651, 637 ms

    Checkoff Question 3: как видно, скорость выполнения алгоритма с разбиениями тем меньше,
чем больше размер блока. Вполне ожидаемый результат, очевидно, что увеличение размера блока
нивелирует разбиение массива. Единственное, что вызывает вопрос - тест номер три, у меня нет
объяснения почему так произошло (результат повторялся несколько раз)
